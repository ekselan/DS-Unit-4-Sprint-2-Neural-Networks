{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4_2_1_A_Copy of LS_DS_431_Intro_to_NN_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dVfaLrjLvxvQ"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "# Neural Networks\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2 Assignment 1*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wxtoY12mwmih"
      },
      "source": [
        "## Define the Following:\n",
        "You can add image, diagrams, whatever you need to ensure that you understand the concepts below.\n",
        "\n",
        "### **Input Layer:** *The portion of a neural network that receives and directly interacts with the data.*\n",
        "\n",
        "\n",
        "### **Hidden Layer:** *The hidden layers are such named because they are not seen and cannot be directly interacted with. These layers include neurons of the NN which in their simplest form can product outputs, but in multi-layered NNs these can pass information to additional layers for advanced computation*\n",
        "\n",
        "\n",
        "### **Output Layer:** *The last layer of a network which outputs values in a format suitable for the problem. For example, you could have continuous outputs for regression problems, or labels between 0 and 1 for classification problems*\n",
        "\n",
        "\n",
        "### **Neuron:** *Somewhat similar to how neurons work in the human brain, neurons in a NN receive inputs and pass on either outputs or signals to the next layer until a threshold is reached. This is somewhat similar to the process in the brain when a human touches something*\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### **Weight:** *A weight in a NN is essentially a value to determine importance, or a type of variable to increase certain values over another. For example, as a NN goes through a training process, the \"weights\" will continue to change until they reach a certain threshold, which would be accurate outputs in a supervised learning situation.*\n",
        "\n",
        "\n",
        "### **Activation Function:** *These decide how much signal to pass on to the next layer, and ultimately determines whether the neuron \"fires\" or not. Could also be thought of as a \"transfer function.\"*\n",
        "\n",
        "\n",
        "### **Node Map:** *A node map is basically a flow chart or visual diagram of the architecture of a NN. These will display the layers (input, hidden and output) and help us understand the structure and differences of NNs.*\n",
        "\n",
        "\n",
        "### **Perceptron:** *Just simple nn that takes n_inputs and provides output, using an activation function. Uses weighted sum of the inputs and adds bias term to produce output. This is what happens in every neuron.*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NXuy9WcWzxa4"
      },
      "source": [
        "## Inputs -> Outputs\n",
        "\n",
        "### Explain the flow of information through a neural network from inputs to outputs. Be sure to include: inputs, weights, bias, and activation functions. How does it all flow from beginning to end?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PlSwIJMC0A8F"
      },
      "source": [
        "#### *A neural network recieves inputs, which would be data for a given problem, and passes this on to the next layer. Then, it will use pre-defined weights to transform those inputs, applying different levels of bias as well as new weight values to pass on to the next layer. These \"passes\" would also be thought of as the activation functions, and with each pass the model will be looking for accuracy compared to the correct output. This would be the learning process, and once a certain threshold is met (set number of passes / layers) it will produce an output, which would be interpretable by the human operating the NN. These outputs could be continuous for regression problems of labels for classification problems.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6sWR43PTwhSk"
      },
      "source": [
        "## Write your own perceptron code that can correctly classify (99.0% accuracy) a NAND gate. \n",
        "\n",
        "| x1 | x2 | y |\n",
        "|----|----|---|\n",
        "| 0  | 0  | 1 |\n",
        "| 1  | 0  | 1 |\n",
        "| 0  | 1  | 1 |\n",
        "| 1  | 1  | 0 |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K51Iq9UWv0LB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "data = { 'x1': [0,1,0,1],\n",
        "         'x2': [0,0,1,1],\n",
        "         'y':  [1,1,1,0]\n",
        "       }\n",
        "\n",
        "df = pd.DataFrame.from_dict(data).astype('int')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Sgh7VFGwnXGH",
        "colab": {}
      },
      "source": [
        "##### Your Code Here #####\n",
        "\n",
        "### Sigmoid activation function and its derivative for updating weights\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "  sx = sigmoid(x)\n",
        "  return sx * (1-sx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-8O6SSUv0LJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "647760a9-8744-4186-ae28-fb01474e209b"
      },
      "source": [
        "### Initialize random weights for inputs\n",
        "\n",
        "np.random.seed(10)\n",
        "\n",
        "weights = 2 * np.random.random((3,1)) - 1\n",
        "weights"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.54264129],\n",
              "       [-0.9584961 ],\n",
              "       [ 0.26729647]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHgHHL3Brl1-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Calculate weighted sum of inputs and weights\n",
        "inputs = np.array([\n",
        "                   data['x1'], \n",
        "                   data['x2'],\n",
        "                   data['y']\n",
        "                   ])\n",
        "\n",
        "correct_outputs = [[1], [1], [1], [0]]\n",
        "\n",
        "\n",
        "weighted_sum = np.dot(inputs.T, weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXsGrjpysXCE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "4ef8f461-4b9b-4399-9caf-84afc91f68e8"
      },
      "source": [
        "### Output the activated value for 1 training epoch\n",
        "\n",
        "activated_output = sigmoid(weighted_sum)\n",
        "activated_output #> Predictions (proba between 0 and 1)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.56642907],\n",
              "       [0.69209624],\n",
              "       [0.33376626],\n",
              "       [0.39750908]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Hh8sd3SuXVu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "83318fa5-d8d7-4fa6-957d-724208d8ab4e"
      },
      "source": [
        "### Take difference of output and true values to calculate error\n",
        "\n",
        "error = correct_outputs - activated_output\n",
        "error"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.43357093],\n",
              "       [ 0.30790376],\n",
              "       [ 0.66623374],\n",
              "       [-0.39750908]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjeBpFVu5BtK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c83c3fbf-0dde-4f08-921e-f6e54a24367d"
      },
      "source": [
        "### Gradient descent\n",
        "\n",
        "adjustments = error * sigmoid_derivative(weighted_sum)\n",
        "print(\"------ Adjustments ------\")\n",
        "print(adjustments)\n",
        "print(\"\\n\")\n",
        "print(\"------ Weights ------\")\n",
        "print(weights)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------ Adjustments ------\n",
            "[[ 0.10647946]\n",
            " [ 0.06561399]\n",
            " [ 0.14814796]\n",
            " [-0.09520168]]\n",
            "\n",
            "\n",
            "------ Weights ------\n",
            "[[ 0.54264129]\n",
            " [-0.9584961 ]\n",
            " [ 0.26729647]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCM-Tfhc5Vyz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c4351f68-8c08-4e4a-cf13-c74e85619d5d"
      },
      "source": [
        "weights += np.dot(inputs, adjustments)\n",
        "\n",
        "print(\"------ New Weights ------\")\n",
        "print(weights)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------ New Weights ------\n",
            "[[ 0.48346591]\n",
            " [-0.85260354]\n",
            " [ 0.9077793 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afKqHy2n5mBo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "7ecab24d-6aa1-4a00-efa5-4740bc4d7081"
      },
      "source": [
        "### Update weights 10,000 times to reduce error\n",
        "\n",
        "for iteration in range(10_000):\n",
        "\n",
        "  weighted_sum = np.dot(inputs.T, weights)\n",
        "\n",
        "  activated_output = sigmoid(weighted_sum)\n",
        "\n",
        "  error = correct_outputs - activated_output\n",
        "\n",
        "  adjustments = error * sigmoid_derivative(weighted_sum)\n",
        "\n",
        "  weights += np.dot(inputs, adjustments)\n",
        "\n",
        "print(\"Weights after training\")\n",
        "print(weights)\n",
        "\n",
        "print(\"Output after training\")\n",
        "print(activated_output)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Weights after training\n",
            "[[-2.40681311]\n",
            " [-2.41407289]\n",
            " [ 7.49088462]]\n",
            "Output after training\n",
            "[[0.99944212]\n",
            " [0.99384319]\n",
            " [0.99379861]\n",
            " [0.00799561]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNa67qi2_gEV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "066d173a-e1b9-42d5-f804-83a6eda4c039"
      },
      "source": [
        "print(\"Correct Outputs\")\n",
        "print(correct_outputs)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correct Outputs\n",
            "[[1], [1], [1], [0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Xf7sdqVs0s4x"
      },
      "source": [
        "## Implement your own Perceptron Class and use it to classify a binary dataset: \n",
        "- [The Pima Indians Diabetes dataset](https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv) \n",
        "\n",
        "You may need to search for other's implementations in order to get inspiration for your own. There are *lots* of perceptron implementations on the internet with varying levels of sophistication and complexity. Whatever your approach, make sure you understand **every** line of your implementation and what its purpose is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3j9W4YHv0LM",
        "colab_type": "code",
        "outputId": "7b07ebad-eb75-4a36-b48f-141bfcc45d20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "diabetes = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv')\n",
        "print(diabetes.shape)\n",
        "diabetes.head()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(768, 9)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n",
              "0            6      148             72  ...                     0.627   50        1\n",
              "1            1       85             66  ...                     0.351   31        0\n",
              "2            8      183             64  ...                     0.672   32        1\n",
              "3            1       89             66  ...                     0.167   21        0\n",
              "4            0      137             40  ...                     2.288   33        1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81_cObi_v0LQ",
        "colab_type": "text"
      },
      "source": [
        "Although neural networks can handle non-normalized data, scaling or normalizing your data will improve your neural network's learning speed. Try to apply the sklearn `MinMaxScaler` or `Normalizer` to your diabetes dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLjxdKwwDMqB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = diabetes.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7CcqmOkv0LR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
        "\n",
        "feats = list(df)[:-1]\n",
        "\n",
        "X = df[feats].values\n",
        "\n",
        "y = df['Outcome'].values\n",
        "\n",
        "# Instantiate normalizer to get values between 0 and 1\n",
        "normalizer = Normalizer()\n",
        "\n",
        "# Apply normalizer\n",
        "X = normalizer.transform(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SufL9MdBBZMZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "65259b61-a542-40cf-db06-f18b1e5d27bb"
      },
      "source": [
        "print(f\"X size: {len(X)} \\ny size: {len(y)}\")\n",
        "print(f\"\\nX type: {type(X)} \\ny type: {type(y)}\")"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X size: 768 \n",
            "y size: 768\n",
            "\n",
            "X type: <class 'numpy.ndarray'> \n",
            "y type: <class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-W0tiX1F1hh2",
        "colab": {}
      },
      "source": [
        " ##### Update this Class #####\n",
        "\n",
        "class Perceptron:\n",
        "    \n",
        "  def __init__(self, niter = 10):\n",
        "      self.niter = niter\n",
        "  \n",
        "  def __sigmoid(self, x):\n",
        "      return 1 / (1 + np.exp(-x))\n",
        "  \n",
        "  def __sigmoid_derivative(self, x):\n",
        "      sx = self.__sigmoid(x)\n",
        "      return sx * (1-sx)\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    \"\"\"Fit training data\n",
        "    X : Training vectors, X.shape : [#samples, #features]\n",
        "    y : Target values, y.shape : [#samples]\n",
        "    \"\"\"\n",
        "  \n",
        "    # Randomly Initialize Weights\n",
        "    np.random.seed(10)\n",
        "\n",
        "    weights = 2 * np.random.random((len(X),1)) - 1\n",
        "\n",
        "    for i in range(self.niter):\n",
        "        # Weighted sum of inputs / weights\n",
        "        weighted_sum = np.dot(X.T, weights)\n",
        "\n",
        "        # Activate!\n",
        "        activated_output = self.__sigmoid(weighted_sum)\n",
        "\n",
        "        # Cac error\n",
        "        error = y - activated_output\n",
        "\n",
        "        # Update the Weights - get adjustments - consider adding a learning\n",
        "        # rate\n",
        "        adjustments = error * self.__sigmoid_derivative(weighted_sum)\n",
        "\n",
        "        weights = weights + (np.dot(X, adjustments))\n",
        "\n",
        "    return weights, error\n",
        "\n",
        "  def predict(self, X, y):\n",
        "    \"\"\"Return class label after unit step\"\"\"\n",
        "    np.random.seed(10)\n",
        "    weights = 2 * np.random.random((len(X),1)) - 1\n",
        "\n",
        "    for i in range(self.niter):\n",
        "        # Weighted sum of inputs / weights\n",
        "        weighted_sum = np.dot(X.T, weights)\n",
        "\n",
        "        # Activate!\n",
        "        activated_output = self.__sigmoid(weighted_sum)\n",
        "\n",
        "        # Cac error\n",
        "        error = y - activated_output\n",
        "\n",
        "        # Update the Weights - get adjustments\n",
        "        adjustments = error * self.__sigmoid_derivative(weighted_sum)\n",
        "\n",
        "        weights = weights + (np.dot(X, adjustments))\n",
        "    \n",
        "    return activated_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Poyvt5tAiNbX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "perceptron = Perceptron()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZlmocoDikqt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "3c101e47-2250-4ee2-bf69-68ca8cfb91de"
      },
      "source": [
        "perceptron.fit(X, y)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 0.69859944,  0.50188433,  0.69859944, ...,  0.50188433,\n",
              "          0.69859944,  0.50188433],\n",
              "        [-0.775174  , -0.97304068, -0.775174  , ..., -0.97304068,\n",
              "         -0.775174  , -0.97304068],\n",
              "        [ 0.36091837,  0.22093047,  0.36091837, ...,  0.22093047,\n",
              "          0.36091837,  0.22093047],\n",
              "        ...,\n",
              "        [ 0.08438265, -0.0666136 ,  0.08438265, ..., -0.0666136 ,\n",
              "          0.08438265, -0.0666136 ],\n",
              "        [ 0.53628534,  0.40293163,  0.53628534, ...,  0.40293163,\n",
              "          0.53628534,  0.40293163],\n",
              "        [ 0.45643412,  0.26578012,  0.45643412, ...,  0.26578012,\n",
              "          0.45643412,  0.26578012]]),\n",
              " array([[ 6.89779065e-02, -3.38717028e-01,  6.89779065e-02, ...,\n",
              "         -3.38717028e-01,  6.89779065e-02, -3.38717028e-01],\n",
              "        [ 0.00000000e+00, -3.79326414e-10,  0.00000000e+00, ...,\n",
              "         -3.79326414e-10,  0.00000000e+00, -3.79326414e-10],\n",
              "        [ 2.22044605e-16, -3.67841820e-08,  2.22044605e-16, ...,\n",
              "         -3.67841820e-08,  2.22044605e-16, -3.67841820e-08],\n",
              "        ...,\n",
              "        [ 6.03586917e-08, -5.67599225e-04,  6.03586917e-08, ...,\n",
              "         -5.67599225e-04,  6.03586917e-08, -5.67599225e-04],\n",
              "        [ 4.39594473e-01, -4.74606053e-01,  4.39594473e-01, ...,\n",
              "         -4.74606053e-01,  4.39594473e-01, -4.74606053e-01],\n",
              "        [ 1.02540224e-08, -7.64866368e-04,  1.02540224e-08, ...,\n",
              "         -7.64866368e-04,  1.02540224e-08, -7.64866368e-04]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arjQe_rdjS75",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "9ecc46e4-8d83-41b3-929b-3f50676e04f4"
      },
      "source": [
        "perceptron.predict(X, y)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.31022094e-01, 3.38717028e-01, 9.31022094e-01, ...,\n",
              "        3.38717028e-01, 9.31022094e-01, 3.38717028e-01],\n",
              "       [1.00000000e+00, 3.79326414e-10, 1.00000000e+00, ...,\n",
              "        3.79326414e-10, 1.00000000e+00, 3.79326414e-10],\n",
              "       [1.00000000e+00, 3.67841820e-08, 1.00000000e+00, ...,\n",
              "        3.67841820e-08, 1.00000000e+00, 3.67841820e-08],\n",
              "       ...,\n",
              "       [9.99999940e-01, 5.67599225e-04, 9.99999940e-01, ...,\n",
              "        5.67599225e-04, 9.99999940e-01, 5.67599225e-04],\n",
              "       [5.60405527e-01, 4.74606053e-01, 5.60405527e-01, ...,\n",
              "        4.74606053e-01, 5.60405527e-01, 4.74606053e-01],\n",
              "       [9.99999990e-01, 7.64866368e-04, 9.99999990e-01, ...,\n",
              "        7.64866368e-04, 9.99999990e-01, 7.64866368e-04]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6QR4oAW1xdyu"
      },
      "source": [
        "## Stretch Goals:\n",
        "\n",
        "- Research \"backpropagation\" to learn how weights get updated in neural networks (tomorrow's lecture). \n",
        "- Implement a multi-layer perceptron. (for non-linearly separable classes)\n",
        "- Try and implement your own backpropagation algorithm.\n",
        "- What are the pros and cons of the different activation functions? How should you decide between them for the different layers of a neural network?"
      ]
    }
  ]
}